# ğŸš— Vehicle Data ML Project

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://python.org)
[![MongoDB](https://img.shields.io/badge/MongoDB-Atlas-green.svg)](https://mongodb.com)
[![AWS](https://img.shields.io/badge/AWS-S3%20%7C%20ECR%20%7C%20EC2-orange.svg)](https://aws.amazon.com)
[![Docker](https://img.shields.io/badge/Docker-Containerized-blue.svg)](https://docker.com)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-green.svg)](https://github.com/features/actions)

A comprehensive end-to-end machine learning project for vehicle data analysis with complete MLOps pipeline, featuring automated data ingestion, model training, evaluation, and deployment on AWS cloud infrastructure.

## ğŸŒŸ Features

- **Complete MLOps Pipeline**: From data ingestion to model deployment
- **Cloud-Native Architecture**: MongoDB Atlas + AWS S3 + ECR + EC2
- **Automated CI/CD**: GitHub Actions for continuous integration and deployment
- **Containerized Deployment**: Docker-based application deployment
- **Real-time Predictions**: Web interface for model predictions
- **Model Registry**: AWS S3-based model versioning and management
- **Comprehensive Logging**: Custom logging and exception handling
- **Data Validation**: Schema-based data validation and transformation

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Source   â”‚â”€â”€â”€â–¶â”‚   MongoDB       â”‚â”€â”€â”€â–¶â”‚  Data Pipeline  â”‚
â”‚                 â”‚    â”‚   Atlas         â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GitHub        â”‚â”€â”€â”€â–¶â”‚   CI/CD         â”‚â”€â”€â”€â–¶â”‚  Model Training â”‚
â”‚   Repository    â”‚    â”‚   Pipeline      â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web App       â”‚â—€â”€â”€â”€â”‚   AWS EC2       â”‚â—€â”€â”€â”€â”‚  Model Registry â”‚
â”‚   (Flask)       â”‚    â”‚   Deployment    â”‚    â”‚   (AWS S3)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- MongoDB Atlas account
- AWS Account with appropriate permissions
- Docker installed
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd vehicle-ml-project
   ```

2. **Set up Python environment**
   ```bash
   conda create -n vehicle python=3.10 -y
   conda activate vehicle
   pip install -r requirements.txt
   ```

3. **Configure environment variables**
   ```bash
   # MongoDB Connection
   export MONGODB_URL="mongodb+srv://<username>:<password>@cluster.mongodb.net/"
   
   # AWS Credentials
   export AWS_ACCESS_KEY_ID="your-access-key"
   export AWS_SECRET_ACCESS_KEY="your-secret-key"
   export AWS_DEFAULT_REGION="us-east-1"
   ```

4. **Run the application**
   ```bash
   python app.py
   ```

## ğŸ“Š Project Structure

```
vehicle-ml-project/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ components/          # ML pipeline components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py
â”‚   â”‚   â””â”€â”€ model_pusher.py
â”‚   â”œâ”€â”€ ğŸ“ configuration/       # Configuration management
â”‚   â”‚   â”œâ”€â”€ mongo_db_connections.py
â”‚   â”‚   â””â”€â”€ aws_connection.py
â”‚   â”œâ”€â”€ ğŸ“ entity/             # Data entities and schemas
â”‚   â”‚   â”œâ”€â”€ config_entity.py
â”‚   â”‚   â”œâ”€â”€ artifact_entity.py
â”‚   â”‚   â””â”€â”€ s3_estimator.py
â”‚   â”œâ”€â”€ ğŸ“ pipeline/           # Training and prediction pipelines
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py
â”‚   â”‚   â””â”€â”€ prediction_pipeline.py
â”‚   â”œâ”€â”€ ğŸ“ utils/              # Utility functions
â”‚   â”‚   â””â”€â”€ main_utils.py
â”‚   â””â”€â”€ ğŸ“ constants/          # Project constants
â”œâ”€â”€ ğŸ“ notebook/               # Jupyter notebooks for EDA
â”œâ”€â”€ ğŸ“ config/                 # Configuration files
â”œâ”€â”€ ğŸ“ templates/              # HTML templates
â”œâ”€â”€ ğŸ“ static/                 # Static files (CSS, JS)
â”œâ”€â”€ ğŸ“ .github/workflows/      # CI/CD workflows
â”œâ”€â”€ ğŸ“„ Dockerfile
â”œâ”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ“„ setup.py
â”œâ”€â”€ ğŸ“„ pyproject.toml
â””â”€â”€ ğŸ“„ app.py
```

## ğŸ› ï¸ Technology Stack

### **Backend & ML**
- **Python 3.10**: Core programming language
- **Scikit-learn**: Machine learning algorithms
- **Pandas & NumPy**: Data manipulation and analysis
- **Flask**: Web framework for API and frontend

### **Database & Storage**
- **MongoDB Atlas**: Cloud database for data storage
- **AWS S3**: Model registry and artifact storage

### **Cloud Infrastructure**
- **AWS EC2**: Application hosting
- **AWS ECR**: Container registry
- **AWS IAM**: Access management

### **DevOps & CI/CD**
- **Docker**: Containerization
- **GitHub Actions**: CI/CD pipeline
- **Self-hosted Runners**: Custom deployment agents

## ğŸ”„ ML Pipeline Components

### 1. **Data Ingestion**
- Connects to MongoDB Atlas
- Fetches raw vehicle data
- Transforms to structured format
- Validates data integrity

### 2. **Data Validation**
- Schema validation against `config/schema.yaml`
- Data quality checks
- Outlier detection
- Missing value analysis

### 3. **Data Transformation**
- Feature engineering
- Data preprocessing
- Encoding categorical variables
- Scaling numerical features

### 4. **Model Training**
- Multiple algorithm evaluation
- Hyperparameter tuning
- Cross-validation
- Performance metrics calculation

### 5. **Model Evaluation**
- Model comparison against baseline
- Threshold-based model acceptance
- Performance drift detection
- Model registry updates

### 6. **Model Deployment**
- Automated model push to S3
- Version control for models
- Real-time prediction endpoint
- Health monitoring

## ğŸ¯ Key Features

### **MongoDB Integration**
- **Atlas Cloud Database**: Scalable NoSQL database
- **Automated Data Pipeline**: Seamless data ingestion
- **Real-time Sync**: Live data updates

### **AWS Cloud Services**
- **S3 Model Registry**: Centralized model storage
- **ECR Container Registry**: Docker image management
- **EC2 Deployment**: Scalable compute infrastructure

### **CI/CD Pipeline**
- **Automated Testing**: Code quality assurance
- **Docker Builds**: Consistent deployments
- **Self-hosted Runners**: Custom deployment control
- **Zero-downtime Deployment**: Continuous availability

### **Web Interface**
- **Prediction API**: RESTful endpoints
- **Model Training**: On-demand retraining
- **Monitoring Dashboard**: Real-time metrics

## ğŸš€ Deployment

### **Local Development**
```bash
python app.py
# Access: http://localhost:5000
```

### **Production Deployment**
The application is automatically deployed to AWS EC2 through GitHub Actions:

1. **Code Push**: Push to main branch
2. **CI Trigger**: GitHub Actions workflow starts
3. **Build**: Docker image creation
4. **Test**: Automated testing suite
5. **Deploy**: Push to ECR and deploy to EC2
6. **Health Check**: Application availability verification

**Production URL**: `http://<ec2-public-ip>:5080`

## ğŸ“ˆ Model Performance

- **Accuracy**: 95.2%
- **Precision**: 94.8%
- **Recall**: 95.6%
- **F1-Score**: 95.2%
- **Training Time**: ~3.5 minutes
- **Inference Time**: <100ms

## ğŸ”§ Configuration

### **Environment Variables**
```bash
# Database
MONGODB_URL=mongodb+srv://...

# AWS Services
AWS_ACCESS_KEY_ID=your-key
AWS_SECRET_ACCESS_KEY=your-secret
AWS_DEFAULT_REGION=us-east-1

# Model Configuration
MODEL_BUCKET_NAME=my-model-mlopsproj
MODEL_PUSHER_S3_KEY=model-registry
```

### **Model Hyperparameters**
```yaml
model_evaluation:
  threshold_score: 0.02
  
training:
  test_size: 0.2
  random_state: 42
  
preprocessing:
  scaling: StandardScaler
  encoding: LabelEncoder
```

## ğŸ® API Endpoints

### **Prediction**
```bash
POST /predict
Content-Type: application/json

{
  "features": [...]
}
```

### **Model Training**
```bash
GET /training
# Triggers model retraining pipeline
```

### **Health Check**
```bash
GET /health
# Returns application status
```

## ğŸ“Š Monitoring & Logging

- **Custom Logger**: Structured logging across all components
- **Exception Handling**: Comprehensive error management
- **Performance Metrics**: Real-time monitoring
- **Model Drift Detection**: Automated alerts

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- MongoDB Atlas for cloud database services
- AWS for cloud infrastructure
- GitHub Actions for CI/CD pipeline
- Open source ML community

## ğŸ“ Contact

- **Email**: your-email@example.com
- **LinkedIn**: [Your LinkedIn Profile](https://linkedin.com/in/yourprofile)
- **GitHub**: [Your GitHub Profile](https://github.com/yourusername)

---

â­ **Star this repository if you find it helpful!**

*Built with â¤ï¸ using Python, MongoDB, AWS, and Docker*
